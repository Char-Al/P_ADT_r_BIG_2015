Le mail "bioinfo_2014-02_30" est globalement en : english
[('english', 0.02202705892781173), ('french', 0.5100024717957234)]
Language by Stop Words : english


+++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++
Le sujet du mail est en : english
Subject : [bioinfo] ESWC 2014 Second Call for Challenge: Semantic Publishing


+++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++
Le paragraphe 1 est en : english
	
** apologies for cross-posting **

==========================================
Le paragraphe 2 est en : english
	==== Second Call for Challenge: Semantic Publishing ====
Challenge Website: http://challenges.2014.eswc-conferences.org/SemPub
Call Web page: http://2014.eswc-conferences.org/important-dates/call-SemPub

==========================================
Le paragraphe 3 est en : english
	** NEWS: 
**     an open in-use task has been added!

==========================================
Le paragraphe 4 est en : english
	11th Extended Semantic Web Conference (ESWC) 2014
Dates: May 25 - 29, 2014
Venue: Anissaras, Crete, Greece
Hashtag: #eswc2014
Feed: @eswc_conf
Site: http://2014.eswc-conferences.org
General Chair: Valentina Presutti (STLab, ISTC-CNR, IT)
Challenge Coordinator: Milan Stankovic (Sepage & Universite Paris-Sorbonne, FR)
Challenge Chairs:
- Angelo Di Iorio (Department of Computer Science and Engineering, University of Bologna, IT)
- Christoph Lange (Enterprise Information Systems, University of Bonn / Fraunhofer IAIS, DE)

==========================================
Le paragraphe 5 est en : french
	MOTIVATION AND OBJECTIVES

==========================================
Le paragraphe 6 est en : english
	Scholarly publishing is increasingly enabling a new wave of applications that better support researchers in disseminating, exploiting and evaluating their results. The potential of publishing scientific papers enriched with semantic information is huge and raises interesting and challenging issues. Semantic Web technologies play a central role in this context, as they can help publishers to make scientific results available in an open format the whole research community can benefit from.

==========================================
Le paragraphe 7 est en : english
	The Semantic Publishing Challenge 2014 is intended to be the first in a series of events at ESWC for producing and exploiting semantic publishing data. The main focus this year is on extracting information and using this information to assess the quality of scientific productions.
Linked open datasets about scientific production exist - e.g. DBLP - but they usually cover basic bibliographic information, which is not sufficient to assess quality. Quality-related information are often hidden and not yet available as LOD. 

==========================================
Le paragraphe 8 est en : english
	There is also a growing interest in alternative forms of publishing scientific data as (semantic) datasets that can be more easily shared, linked to each other, and reasoned on. Alternative metrics for scientific impact are also gaining relevance.

==========================================
Le paragraphe 9 est en : english
	We are seeking the most innovative and impacting applications in this emerging contexts. 

==========================================
Le paragraphe 10 est en : english
	TARGET AUDIENCE

==========================================
Le paragraphe 11 est en : english
	The Challenge is open to everyone from industry and academia.

==========================================
Le paragraphe 12 est en : english
	TASKS

==========================================
Le paragraphe 13 est en : english
	The Challenge includes three tasks. Participants can participate in as many tasks as they like.

==========================================
Le paragraphe 14 est en : english
	= Extraction Tasks =

==========================================
Le paragraphe 15 est en : english
	We ask challengers to automatically annotate a set of multi-format and multi-source input documents and to produce a Linked Open Dataset that fully describes these documents, their context, and relevant parts of their content. The evaluation will consist of evaluating a set of queries against the produced dataset to assess its correctness and completeness. The input dataset will be split in two parts: a training/testing part and an evaluation part, which will disclosed a few days before the submission deadline. Participants will be asked to run their tool on the evaluation dataset and to produce the final Linked Open Dataset.

==========================================
Le paragraphe 16 est en : english
	== Task 1: Extraction and assessment of workshop proceedings information ==

==========================================
Le paragraphe 17 est en : english
	Participants are required to extract information from a set of HTML tables of contents, partly including microformat and RDFa annotations but not necessarily being valid HTML, of selected computer science workshop proceedings published with the CEUR-WS.org open access service. The extracted information is expected to answer queries about the quality of these workshops, for instance by measuring their growth, longevity, connection with other events, distribution of papers and authors.

==========================================
Le paragraphe 18 est en : english
	== Task 2: Extraction and characterization of citations ==

==========================================
Le paragraphe 19 est en : english
	Participants are required to extract information about the citations in scientific journals and their relevance. Input documents are in XML JATS and TaxPub, an official extension of JATS customized for taxonomic treatments, and selected from the PubMedCentral Open Access Subset and the Pensoft Biodiversity Data Journal and ZooKeys archive. The extracted information is expected to be used for assessing the value of citations, for instance by considering their position in the paper, their co-location with other citations or their purpose.

==========================================
Le paragraphe 20 est en : english
	== In-use Task 3: Semantic technologies in improving scientific production ==

==========================================
Le paragraphe 21 est en : english
	Participants are asked to submit demos that showcase the potential of Semantic Web technology for enhancing and assessing the quality of scientific production. 

==========================================
Le paragraphe 22 est en : english
	The task has a completely open structure and is, in particular, independent from tasks 1 and 2: participants are free to decide which tool to show and which dataset to use.

==========================================
Le paragraphe 23 est en : english
	The evaluation will be different from other tasks and will consist of two phases: after a first round of review, a number of submissions will be invited to demo their work at ESWC. The final decision will be taken at the Conference by a jury formed of PC members present at the event and other invited experts.

==========================================
Le paragraphe 24 est en : english
	Further details are available at: http://challenges.2014.eswc-conferences.org/index.php/SemPub/Task3

==========================================
Le paragraphe 25 est en : french
	EVALUATION

==========================================
Le paragraphe 26 est en : english
	= Extraction Tasks 1 and 2 =

==========================================
Le paragraphe 27 est en : english
	Participants will be requested to submit the LOD that their tool produces from the evaluation dataset, as well as a paper that describes their approach. They will also be given a set of queries in natural language form and will be asked to translate those queries into a SPARQL form that works on their LOD.

==========================================
Le paragraphe 28 est en : english
	The results of the queries on the produced LOD will be compared with the expected output, and precision and recall will be measured to identify the best performing approach. Separately, the most original approach will be assigned by the Program Committee.

==========================================
Le paragraphe 29 est en : english
	= In-use Task 3 =

==========================================
Le paragraphe 30 est en : french
	Participants are required to submit a paper description as for tasks 1 and 2 and a demo version of the tool (open source appreciated but not mandatory).

==========================================
Le paragraphe 31 est en : english
	The evaluation will consist of two phases: after a first round of review, a number of submissions will be invited to demo their work at ESWC. The final decision will be taken at the Conference by a jury formed of PC members present at the event and other invited experts. The winner will be selected according to its potential impact, originality, breakthrough, the quality of the demo, and the appropriateness for ESWC.

==========================================
Le paragraphe 32 est en : english
	Further details about the evaluation are provided on the challenge wiki.

==========================================
Le paragraphe 33 est en : english
	FEEDBACK AND DISCUSSION

==========================================
Le paragraphe 34 est en : english
	A discussion group is open for participants to ask questions and to receive updates about the challenge (see link at bottom). Participants are invited to subscribe to this group as soon as possible and to communicate their intention to participate. They are also invited to use this channel to discuss problems in the input dataset and to suggest changes.

==========================================
Le paragraphe 35 est en : english
	JUDGING AND PRIZES

==========================================
Le paragraphe 36 est en : english
	The Program Committee and the chairs will select a number of submissions conforming to the challenge requirements that will be invited to present their work. Submissions accepted for presentation will receive constructive reviews from the Program Committee, they will be included in the Springer LNCS post-proceedings of ESWC, and they will also have a presentation slot in a poster session dedicated to the challenge. 

==========================================
Le paragraphe 37 est en : english
	In addition, the winners will present their work in a special slot of the main program of ESWC and will be invited to submit a revised and extended paper to a dedicated Semantic Web Journal special issue.

==========================================
Le paragraphe 38 est en : english
	Five winners will be selected. For each of Tasks 1 and 2 we will select:
* best performing tool, given to the paper which will get the highest score in the evaluation
* most original approach, selected by the Challenge Committee with the reviewing process

==========================================
Le paragraphe 39 est en : english
	The winner of Task 3 will be selected by the jury according to its potential impact, originality, breakthrough, the quality of the demo, and the appropriateness for ESWC.

==========================================
Le paragraphe 40 est en : english
	Winners will be selected only for tasks with at least 3 participants. In any case all submissions will be reviewed and, if accepted, published in ESWC post-proceedings.

==========================================
Le paragraphe 41 est en : english
	An amount of 700 Euro has already been secured for the final prize. We are currently working on securing further funding.

==========================================
Le paragraphe 42 est en : english
	 
HOW TO PARTICIPATE

==========================================
Le paragraphe 43 est en : english
	Participants are required to submit:
* Abstract: no more than 200 words.
* Description: It should explain the details of the automated annotation system, including why the system is innovative, how it uses Semantic Web technology, what features or functions the system provides, what design choices were made and what lessons were learned. The description should also summarize how participants have addressed the evaluation tasks. An outlook towards how the data could be consumed is appreciated but not strictly required. Papers must be submitted in PDF format, following the style of the Springer's Lecture Notes in Computer Science (LNCS) series (http://www.springer.com/computer/lncs/lncs+authors), and not exceeding 5 pages in length.

==========================================
Le paragraphe 44 est en : english
	Submissions for task 1 and task 2 also have to include:
* The Linked Open Dataset produced by the tool on the evaluation dataset (as a file or as a URL, in Turtle or RDF/XML). 
* A set of SPARQL queries that work on that LOD and correspond to the natural language queries provided as input
* Participants will also be asked to submit their tool (source and/or binaries, or a link these can be downloaded from, or a web service URL) for verification purposes.

==========================================
Le paragraphe 45 est en : english
	Submissions for the in-use task 3 have to include:
* a demo version of the tool. The demo must be made available along with the paper submission but participants are allowed to refine it until the presentation at ESWC-14. 

==========================================
Le paragraphe 46 est en : english
	All papers submissions should be provided via EasyChair:

==========================================
Le paragraphe 47 est en : english
	https://www.easychair.org/conferences/?conf=eswc2014-challenges

==========================================
Le paragraphe 48 est en : english
	MAILING LIST

==========================================
Le paragraphe 49 est en : english
	We invite the potential participants to subscribe to our mailing list in order to be kept up to date with the latest news related to the challenge. 

==========================================
Le paragraphe 50 est en : english
	https://lists.sti2.org/mailman/listinfo/eswc2014-sempub-challenge

==========================================
Le paragraphe 51 est en : english
	IMPORTANT DATES

==========================================
Le paragraphe 52 est en : english
	* December 3, 2013: Publication of the full description of the extraction tasks 1 and 2, rules and queries; publication of the training/testing dataset 
* January 31, 2014, 23:59 CET: Deadline for making remarks to the task 1 and 2 training/testing datasets
* February 5, 2014: Publication of the final task 1 and 2 training/testing datasets
* March 7, 2014, 23:59 CET: Abstract submission
* March 11, 2014: Publication of the task 1 and 2 evaluation dataset
* March 14, 2014, 23:59 CET: Submission due
* April 9, 2014, 23:59 CET: Notification of acceptance
* May 27-29, 2014: Demo at ESWC-14, and winner selection

==========================================
Le paragraphe 53 est en : english
	PROGRAM COMMITTEE

==========================================
Le paragraphe 54 est en : english
	Soren Auer (University of Bonn / Fraunhofer IAIS, DE) (supervisor)
Chris Bizer (University of Mannheim, DE)
Sarven Capadisli (University of Leipzig, DE)
Alexander Constantin (University of Manchester, UK)
Jeremy Debattista (University of Bonn / Fraunhofer IAIS, DE)
Alexander Garcia Castro (Florida State University, US)
Leyla Jael Garcia Castro (Bundeswehr University of Munich, DE)
Paul Groth (VU University of Amsterdam, Netherlands)
Rinke Hoekstra (VU University of Amsterdam, Netherlands)
Aidan Hogan (DCC, Universidad de Chile)
Evangelos Milios (Dalhousie University, CA)
Lyubomir Penev (Pensoft Publishers, BG)
Robert Stevens (University of Manchester, UK)
Jun Zhao (Lancaster University, UK)

==========================================
Le paragraphe 55 est en : english
	We are inviting further members.


==========================================


+++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++++++++++++++++
La phrase 1 est en : english
	
** apologies for cross-posting **

==== Second Call for Challenge: Semantic Publishing ====
Challenge Website: http://challenges.2014.eswc-conferences.org/SemPub
Call Web page: http://2014.eswc-conferences.org/important-dates/call-SemPub

** NEWS: 
**     an open in-use task has been added!
==========================================
La phrase 2 est en : english
	11th Extended Semantic Web Conference (ESWC) 2014
Dates: May 25 - 29, 2014
Venue: Anissaras, Crete, Greece
Hashtag: #eswc2014
Feed: @eswc_conf
Site: http://2014.eswc-conferences.org
General Chair: Valentina Presutti (STLab, ISTC-CNR, IT)
Challenge Coordinator: Milan Stankovic (Sepage & Universite Paris-Sorbonne, FR)
Challenge Chairs:
- Angelo Di Iorio (Department of Computer Science and Engineering, University of Bologna, IT)
- Christoph Lange (Enterprise Information Systems, University of Bonn / Fraunhofer IAIS, DE)


MOTIVATION AND OBJECTIVES

Scholarly publishing is increasingly enabling a new wave of applications that better support researchers in disseminating, exploiting and evaluating their results.
==========================================
La phrase 3 est en : english
	The potential of publishing scientific papers enriched with semantic information is huge and raises interesting and challenging issues.
==========================================
La phrase 4 est en : english
	Semantic Web technologies play a central role in this context, as they can help publishers to make scientific results available in an open format the whole research community can benefit from.
==========================================
La phrase 5 est en : english
	The Semantic Publishing Challenge 2014 is intended to be the first in a series of events at ESWC for producing and exploiting semantic publishing data.
==========================================
La phrase 6 est en : english
	The main focus this year is on extracting information and using this information to assess the quality of scientific productions.
==========================================
La phrase 7 est en : english
	Linked open datasets about scientific production exist - e.g.
==========================================
La phrase 8 est en : english
	DBLP - but they usually cover basic bibliographic information, which is not sufficient to assess quality.
==========================================
La phrase 9 est en : english
	Quality-related information are often hidden and not yet available as LOD.
==========================================
La phrase 10 est en : english
	There is also a growing interest in alternative forms of publishing scientific data as (semantic) datasets that can be more easily shared, linked to each other, and reasoned on.
==========================================
La phrase 11 est en : english
	Alternative metrics for scientific impact are also gaining relevance.
==========================================
La phrase 12 est en : english
	We are seeking the most innovative and impacting applications in this emerging contexts.
==========================================
La phrase 13 est en : english
	TARGET AUDIENCE

The Challenge is open to everyone from industry and academia.
==========================================
La phrase 14 est en : english
	TASKS

The Challenge includes three tasks.
==========================================
La phrase 15 est en : english
	Participants can participate in as many tasks as they like.
==========================================
La phrase 16 est en : english
	= Extraction Tasks =

We ask challengers to automatically annotate a set of multi-format and multi-source input documents and to produce a Linked Open Dataset that fully describes these documents, their context, and relevant parts of their content.
==========================================
La phrase 17 est en : english
	The evaluation will consist of evaluating a set of queries against the produced dataset to assess its correctness and completeness.
==========================================
La phrase 18 est en : english
	The input dataset will be split in two parts: a training/testing part and an evaluation part, which will disclosed a few days before the submission deadline.
==========================================
La phrase 19 est en : english
	Participants will be asked to run their tool on the evaluation dataset and to produce the final Linked Open Dataset.
==========================================
La phrase 20 est en : english
	== Task 1: Extraction and assessment of workshop proceedings information ==

Participants are required to extract information from a set of HTML tables of contents, partly including microformat and RDFa annotations but not necessarily being valid HTML, of selected computer science workshop proceedings published with the CEUR-WS.org open access service.
==========================================
La phrase 21 est en : english
	The extracted information is expected to answer queries about the quality of these workshops, for instance by measuring their growth, longevity, connection with other events, distribution of papers and authors.
==========================================
La phrase 22 est en : english
	== Task 2: Extraction and characterization of citations ==

Participants are required to extract information about the citations in scientific journals and their relevance.
==========================================
La phrase 23 est en : english
	Input documents are in XML JATS and TaxPub, an official extension of JATS customized for taxonomic treatments, and selected from the PubMedCentral Open Access Subset and the Pensoft Biodiversity Data Journal and ZooKeys archive.
==========================================
La phrase 24 est en : english
	The extracted information is expected to be used for assessing the value of citations, for instance by considering their position in the paper, their co-location with other citations or their purpose.
==========================================
La phrase 25 est en : english
	== In-use Task 3: Semantic technologies in improving scientific production ==

Participants are asked to submit demos that showcase the potential of Semantic Web technology for enhancing and assessing the quality of scientific production.
==========================================
La phrase 26 est en : english
	The task has a completely open structure and is, in particular, independent from tasks 1 and 2: participants are free to decide which tool to show and which dataset to use.
==========================================
La phrase 27 est en : english
	The evaluation will be different from other tasks and will consist of two phases: after a first round of review, a number of submissions will be invited to demo their work at ESWC.
==========================================
La phrase 28 est en : english
	The final decision will be taken at the Conference by a jury formed of PC members present at the event and other invited experts.
==========================================
La phrase 29 est en : english
	Further details are available at: http://challenges.2014.eswc-conferences.org/index.php/SemPub/Task3


EVALUATION

= Extraction Tasks 1 and 2 =

Participants will be requested to submit the LOD that their tool produces from the evaluation dataset, as well as a paper that describes their approach.
==========================================
La phrase 30 est en : english
	They will also be given a set of queries in natural language form and will be asked to translate those queries into a SPARQL form that works on their LOD.
==========================================
La phrase 31 est en : english
	The results of the queries on the produced LOD will be compared with the expected output, and precision and recall will be measured to identify the best performing approach.
==========================================
La phrase 32 est en : english
	Separately, the most original approach will be assigned by the Program Committee.
==========================================
La phrase 33 est en : english
	= In-use Task 3 =

Participants are required to submit a paper description as for tasks 1 and 2 and a demo version of the tool (open source appreciated but not mandatory).
==========================================
La phrase 34 est en : english
	The evaluation will consist of two phases: after a first round of review, a number of submissions will be invited to demo their work at ESWC.
==========================================
La phrase 35 est en : english
	The final decision will be taken at the Conference by a jury formed of PC members present at the event and other invited experts.
==========================================
La phrase 36 est en : english
	The winner will be selected according to its potential impact, originality, breakthrough, the quality of the demo, and the appropriateness for ESWC.
==========================================
La phrase 37 est en : english
	Further details about the evaluation are provided on the challenge wiki.
==========================================
La phrase 38 est en : english
	FEEDBACK AND DISCUSSION

A discussion group is open for participants to ask questions and to receive updates about the challenge (see link at bottom).
==========================================
La phrase 39 est en : english
	Participants are invited to subscribe to this group as soon as possible and to communicate their intention to participate.
==========================================
La phrase 40 est en : english
	They are also invited to use this channel to discuss problems in the input dataset and to suggest changes.
==========================================
La phrase 41 est en : english
	JUDGING AND PRIZES

The Program Committee and the chairs will select a number of submissions conforming to the challenge requirements that will be invited to present their work.
==========================================
La phrase 42 est en : english
	Submissions accepted for presentation will receive constructive reviews from the Program Committee, they will be included in the Springer LNCS post-proceedings of ESWC, and they will also have a presentation slot in a poster session dedicated to the challenge.
==========================================
La phrase 43 est en : english
	In addition, the winners will present their work in a special slot of the main program of ESWC and will be invited to submit a revised and extended paper to a dedicated Semantic Web Journal special issue.
==========================================
La phrase 44 est en : english
	Five winners will be selected.
==========================================
La phrase 45 est en : english
	For each of Tasks 1 and 2 we will select:
* best performing tool, given to the paper which will get the highest score in the evaluation
* most original approach, selected by the Challenge Committee with the reviewing process

The winner of Task 3 will be selected by the jury according to its potential impact, originality, breakthrough, the quality of the demo, and the appropriateness for ESWC.
==========================================
La phrase 46 est en : english
	Winners will be selected only for tasks with at least 3 participants.
==========================================
La phrase 47 est en : english
	In any case all submissions will be reviewed and, if accepted, published in ESWC post-proceedings.
==========================================
La phrase 48 est en : english
	An amount of 700 Euro has already been secured for the final prize.
==========================================
La phrase 49 est en : english
	We are currently working on securing further funding.
==========================================
La phrase 50 est en : english
	HOW TO PARTICIPATE

Participants are required to submit:
* Abstract: no more than 200 words.
==========================================
La phrase 51 est en : english
	* Description: It should explain the details of the automated annotation system, including why the system is innovative, how it uses Semantic Web technology, what features or functions the system provides, what design choices were made and what lessons were learned.
==========================================
La phrase 52 est en : english
	The description should also summarize how participants have addressed the evaluation tasks.
==========================================
La phrase 53 est en : english
	An outlook towards how the data could be consumed is appreciated but not strictly required.
==========================================
La phrase 54 est en : english
	Papers must be submitted in PDF format, following the style of the Springer's Lecture Notes in Computer Science (LNCS) series (http://www.springer.com/computer/lncs/lncs+authors), and not exceeding 5 pages in length.
==========================================
La phrase 55 est en : english
	Submissions for task 1 and task 2 also have to include:
* The Linked Open Dataset produced by the tool on the evaluation dataset (as a file or as a URL, in Turtle or RDF/XML).
==========================================
La phrase 56 est en : english
	* A set of SPARQL queries that work on that LOD and correspond to the natural language queries provided as input
* Participants will also be asked to submit their tool (source and/or binaries, or a link these can be downloaded from, or a web service URL) for verification purposes.
==========================================
La phrase 57 est en : english
	Submissions for the in-use task 3 have to include:
* a demo version of the tool.
==========================================
La phrase 58 est en : english
	The demo must be made available along with the paper submission but participants are allowed to refine it until the presentation at ESWC-14.
==========================================
La phrase 59 est en : english
	All papers submissions should be provided via EasyChair:

https://www.easychair.org/conferences/?conf=eswc2014-challenges


MAILING LIST

We invite the potential participants to subscribe to our mailing list in order to be kept up to date with the latest news related to the challenge.
==========================================
La phrase 60 est en : english
	https://lists.sti2.org/mailman/listinfo/eswc2014-sempub-challenge


IMPORTANT DATES

* December 3, 2013: Publication of the full description of the extraction tasks 1 and 2, rules and queries; publication of the training/testing dataset 
* January 31, 2014, 23:59 CET: Deadline for making remarks to the task 1 and 2 training/testing datasets
* February 5, 2014: Publication of the final task 1 and 2 training/testing datasets
* March 7, 2014, 23:59 CET: Abstract submission
* March 11, 2014: Publication of the task 1 and 2 evaluation dataset
* March 14, 2014, 23:59 CET: Submission due
* April 9, 2014, 23:59 CET: Notification of acceptance
* May 27-29, 2014: Demo at ESWC-14, and winner selection


PROGRAM COMMITTEE

Soren Auer (University of Bonn / Fraunhofer IAIS, DE) (supervisor)
Chris Bizer (University of Mannheim, DE)
Sarven Capadisli (University of Leipzig, DE)
Alexander Constantin (University of Manchester, UK)
Jeremy Debattista (University of Bonn / Fraunhofer IAIS, DE)
Alexander Garcia Castro (Florida State University, US)
Leyla Jael Garcia Castro (Bundeswehr University of Munich, DE)
Paul Groth (VU University of Amsterdam, Netherlands)
Rinke Hoekstra (VU University of Amsterdam, Netherlands)
Aidan Hogan (DCC, Universidad de Chile)
Evangelos Milios (Dalhousie University, CA)
Lyubomir Penev (Pensoft Publishers, BG)
Robert Stevens (University of Manchester, UK)
Jun Zhao (Lancaster University, UK)

We are inviting further members.

==========================================
